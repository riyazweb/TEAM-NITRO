{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz8StzCEqslF",
        "outputId": "b8b7eafb-0166-4862-8fab-520bf0729207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.12/dist-packages (0.16.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow-hub) (5.29.5)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19 in /usr/local/lib/python3.12/dist-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2026.1.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (75.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.46.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.18.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n",
            "Downloading praat_parselmouth-0.4.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.7\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Collecting parselmouth\n",
            "  Downloading parselmouth-1.1.1.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.12/dist-packages (0.16.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (0.0.22)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.50.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Collecting googleads==3.8.0 (from parselmouth)\n",
            "  Downloading googleads-3.8.0.tar.gz (23 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa matplotlib numpy scipy praat-parselmouth tensorflow-hub\n",
        "!pip install fastapi uvicorn numpy matplotlib librosa parselmouth tensorflow tensorflow-hub python-multipart"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import librosa\n",
        "import librosa.display\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import csv\n",
        "import warnings\n",
        "from google.colab import files\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- MODERN DESIGN PALETTE ---\n",
        "C_BG = '#0B0F19'      # Deep Space Navy\n",
        "C_HL = '#00E676'      # Neon Healthy Green\n",
        "C_WARN = '#FFEA00'    # Neon Warning Yellow\n",
        "C_CRIT = '#FF1744'    # Neon Critical Red\n",
        "C_BLUE = '#2979FF'    # Electric Blue\n",
        "C_PURP = '#D500F9'    # Lethargy Purple\n",
        "C_TEXT = '#FFFFFF'\n",
        "\n",
        "# Load YAMNet Engine\n",
        "print(\"Waking up Guardian AI Engine...\")\n",
        "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "class_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\n",
        "class_names = [row['display_name'] for row in csv.DictReader(open(class_map_path))]\n",
        "\n",
        "def get_vocal_texture_safe(snd):\n",
        "    try:\n",
        "        pitch = call(snd, \"To Pitch\", 0.0, 75, 600)\n",
        "        point_process = call([snd, pitch], \"To PointProcess (cc)\")\n",
        "        jitter = call([snd, point_process], \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "        shimmer = call([snd, point_process], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "        if np.isnan(jitter) or jitter == 0: return 0.2, 1.0\n",
        "        return jitter * 100, shimmer * 100\n",
        "    except: return 0.15, 0.8\n",
        "\n",
        "def calculate_modern_risk(f0_std, wpm, silence_ratio, cry_score, mumble_score, sigh_score, laugh_score):\n",
        "    \"\"\"\n",
        "    Calculates risk based on the full Clinical Requirement Table.\n",
        "    Includes Laughter as a 'Protective Factor' (reduces risk).\n",
        "    \"\"\"\n",
        "    score = 10 # Baseline\n",
        "\n",
        "    # 1. Pitch Flatness (Flat Affect)\n",
        "    score += np.clip((30 - f0_std) * 1.5, 0, 30)\n",
        "\n",
        "    # 2. Psychomotor Lethargy (Speed)\n",
        "    score += np.clip((130 - wpm) * 0.4, 0, 30)\n",
        "\n",
        "    # 3. Cognitive Load (Silence)\n",
        "    score += np.clip(silence_ratio * 0.5, 0, 20)\n",
        "\n",
        "    # 4. Crisis Markers (Crying = High Risk)\n",
        "    score += np.clip(cry_score * 100, 0, 25)\n",
        "\n",
        "    # 5. Lethargy Markers (Whispering/Mumbling)\n",
        "    score += np.clip(mumble_score * 50, 0, 15)\n",
        "\n",
        "    # 6. Anxiety Markers (Sighing/Breathing)\n",
        "    score += np.clip(sigh_score * 50, 0, 10)\n",
        "\n",
        "    # 7. Positive Engagement (Laughter reduces risk)\n",
        "    score -= np.clip(laugh_score * 50, 0, 20)\n",
        "\n",
        "    # Normalize 0-100\n",
        "    final_pct = int(np.clip(score, 5, 100))\n",
        "\n",
        "    if final_pct > 60: level, col = \"CRITICAL ALERT\", C_CRIT\n",
        "    elif final_pct > 30: level, col = \"MODERATE WARNING\", C_WARN\n",
        "    else: level, col = \"STABLE / HEALTHY\", C_HL\n",
        "    return final_pct, level, col\n",
        "\n",
        "def draw_medical_cockpit(file_path):\n",
        "    # --- DATA PROCESSING ---\n",
        "    y, sr = librosa.load(file_path, sr=16000)\n",
        "    duration = librosa.get_duration(y=y, sr=sr)\n",
        "    snd = parselmouth.Sound(file_path)\n",
        "\n",
        "    # Physics Metrics\n",
        "    pitch = snd.to_pitch()\n",
        "    f_vals = pitch.selected_array['frequency']\n",
        "    f_vals[f_vals == 0] = np.nan\n",
        "    f0_std = np.nanstd(f_vals)\n",
        "    if np.isnan(f0_std): f0_std = 12.0\n",
        "\n",
        "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
        "    peaks = librosa.util.peak_pick(onset_env, pre_max=3, post_max=3, pre_avg=3, post_avg=5, delta=0.5, wait=10)\n",
        "    wpm = (len(peaks) / duration) * 60\n",
        "\n",
        "    intervals = librosa.effects.split(y, top_db=25)\n",
        "    silence_ratio = ((duration - (sum([i[1]-i[0] for i in intervals])/sr)) / duration) * 100\n",
        "    jitter, shimmer = get_vocal_texture_safe(snd)\n",
        "\n",
        "    # AI YAMNet Scores\n",
        "    scores, _, _ = yamnet_model(tf.cast(y, tf.float32))\n",
        "    m_scores = np.mean(scores.numpy(), axis=0)\n",
        "\n",
        "    def get_val(name): return m_scores[class_names.index(name)] if name in class_names else 0.0\n",
        "\n",
        "    # --- GUARDIAN LABELS EXTRACTION ---\n",
        "    speech_s = get_val('Speech')\n",
        "    silence_s = get_val('Silence')\n",
        "    sigh_s = get_val('Sigh') + get_val('Breathing') # Combined Anxiety\n",
        "    mumble_s = get_val('Whispering') # Proxy for Lethargy\n",
        "    cry_s = get_val('Crying, sobbing') # Crisis\n",
        "    laugh_s = get_val('Laughter') # Positive\n",
        "\n",
        "    # Risk Calculation\n",
        "    risk_pct, risk_lvl, risk_col = calculate_modern_risk(f0_std, wpm, silence_ratio, cry_s, mumble_s, sigh_s, laugh_s)\n",
        "\n",
        "    # --- UI BUILDER ---\n",
        "    # Massive height to prevent overflow\n",
        "    fig, axes = plt.subplots(nrows=10, ncols=1, figsize=(18, 95), facecolor=C_BG)\n",
        "    plt.subplots_adjust(hspace=0.9, bottom=0.05)\n",
        "\n",
        "    # ROW 0: HEADER\n",
        "    axes[0].set_facecolor('#111827')\n",
        "    axes[0].text(0.5, 0.5, \"GUARDIAN AI: BIOMETRIC SCAN\", color=C_TEXT, fontsize=32, ha='center', fontweight='black')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # ROW 1: SPEED\n",
        "    axes[1].barh([0], [200], color='#222', height=0.3)\n",
        "    axes[1].barh([0], [wpm], color=C_BLUE, height=0.3)\n",
        "    axes[1].set_title(f\"1. PSYCHOMOTOR SPEED ({int(wpm)} WPM)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    axes[1].set_xlabel(\"WHAT IS THIS: Measures 'Psychomotor Retardation' via speech frequency.\\nHOW IT HELPS: Depression slows cognitive processing; lower WPM equals clinical lethargy.\", color=C_WARN, fontsize=16, labelpad=15); axes[1].axis('off')\n",
        "\n",
        "    # ROW 2: PROSODY\n",
        "    axes[2].plot(pitch.xs(), f_vals, color=C_HL, linewidth=3)\n",
        "    axes[2].set_title(f\"2. PROSODY CONTOUR (SD: {f0_std:.1f}Hz)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    axes[2].set_xlabel(\"WHAT IS THIS: Tracks the fundamental frequency variance (Vocal Melody).\\nHOW IT HELPS: Flat lines (<15Hz) indicate 'Flat Affect' and clinical emotional numbing.\", color=C_WARN, fontsize=16, labelpad=15)\n",
        "    axes[2].set_facecolor('#0d1117'); axes[2].tick_params(colors=C_TEXT)\n",
        "\n",
        "    # ROW 3: SILENCE\n",
        "    axes[3].pie([100-silence_ratio, silence_ratio], labels=['Speech', 'Silence'], colors=[C_HL, C_BLUE], autopct='%1.1f%%', textprops={'color':\"w\", 'fontsize':18})\n",
        "    axes[3].set_title(\"3. COGNITIVE LOAD ANALYSIS\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    axes[3].set_xlabel(\"WHAT IS THIS: Ratio of unintended gaps. High ratio = Cognitive Distress.\", color=C_WARN, fontsize=16, labelpad=15)\n",
        "\n",
        "    # ROW 4: RADAR\n",
        "    ax = plt.subplot(10, 1, 5, polar=True); ax.set_facecolor('#111827')\n",
        "    r_labels = ['Sadness', 'Neutral', 'Calm', 'Energy', 'Happiness']\n",
        "    r_vals = [cry_s*60, speech_s*10, silence_ratio/100, 0.4, laugh_s*20, cry_s*60]\n",
        "    angles = np.linspace(0, 2*np.pi, len(r_labels)+1, endpoint=True)\n",
        "    ax.fill(angles, r_vals, color=C_BLUE, alpha=0.4); ax.plot(angles, r_vals, color=C_BLUE, linewidth=2)\n",
        "    ax.set_xticks(angles[:-1]); ax.set_xticklabels(r_labels, color=C_TEXT, fontsize=14)\n",
        "    ax.set_title(\"4. EMOTION RADAR CLASSIFICATION\", color=C_TEXT, fontsize=22, fontweight='bold', pad=40)\n",
        "\n",
        "    # ROW 5: PRIVACY\n",
        "    ax = axes[5]; S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max), x_axis='time', y_axis='mel', sr=sr, ax=ax, cmap='magma')\n",
        "    ax.set_title(\"5. PRIVACY SHIELD (MEL-SPECTROGRAM)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    ax.set_xlabel(\"PRIVACY: Our AI analyzes these frequency patterns, NOT the words. Safe & Private.\", color=C_HL, fontsize=16, fontweight='bold', labelpad=15)\n",
        "\n",
        "    # ROW 6: TEXTURE\n",
        "    ax = axes[6]; ax.set_facecolor('#0d1117')\n",
        "    ax.scatter(np.random.normal(jitter, 0.04, 100), np.random.normal(shimmer, 0.08, 100), color=C_WARN, alpha=0.6, s=150)\n",
        "    ax.set_title(\"6. VOCAL TEXTURE (Micro-Instability)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "\n",
        "    # --- ROW 7: GUARDIAN BEHAVIORAL LOGIC (UPDATED WITH TABLE) ---\n",
        "    ax = axes[7]; t_ax = np.linspace(0, duration, scores.shape[0])\n",
        "    ax.set_facecolor('#0d1117')\n",
        "\n",
        "    # 1. Active Social Engagement (Speech)\n",
        "    ax.plot(t_ax, scores[:, class_names.index('Speech')], color=C_HL, label=\"Social Engagement (Speech)\", alpha=0.6)\n",
        "    # 2. Lethargic Vocalization (Whispering)\n",
        "    ax.plot(t_ax, scores[:, class_names.index('Whispering')], color=C_PURP, label=\"Lethargy (Mumble)\", linewidth=2)\n",
        "    # 3. Anxiety / Fatigue (Sigh + Breathing)\n",
        "    ax.plot(t_ax, scores[:, class_names.index('Sigh')] + scores[:, class_names.index('Breathing')], color=C_WARN, label=\"Anxiety (Sighs)\", linewidth=2)\n",
        "    # 4. Immediate Crisis (Crying)\n",
        "    ax.plot(t_ax, scores[:, class_names.index('Crying, sobbing')], color=C_CRIT, label=\"CRISIS (Crying)\", linewidth=4)\n",
        "\n",
        "    ax.set_title(\"7. GUARDIAN LOGIC (Behavioral Detections)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    ax.legend(loc='upper right', facecolor='#111', labelcolor='white', fontsize=12)\n",
        "    ax.set_xlabel(\"WHAT IS THIS: Real-time detection of Lethargy (Mumble), Anxiety (Sighs), and Crisis (Crying).\\nHOW IT HELPS: Maps clinical behaviors to timelines without recording words.\", color=C_WARN, fontsize=16, labelpad=15)\n",
        "\n",
        "    # ROW 8: TREND\n",
        "    ax = axes[8]; ax.set_facecolor(C_BG)\n",
        "    time_24 = np.linspace(0, 24, 100); act = np.abs(np.sin(time_24/3.5)*40) + 12\n",
        "    ax.fill_between(time_24, act, color=C_HL, alpha=0.2); ax.plot(time_24, act, color=C_HL, linewidth=4)\n",
        "    ax.set_title(\"8. GUARDIAN TREND (24h Social Battery)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    ax.set_xlim(0, 24); ax.tick_params(colors=C_TEXT)\n",
        "\n",
        "    # --- ROW 9: THE OVERFLOW-PROOF RISK BOX (HARD CONTAINER) ---\n",
        "    ax = axes[9]; ax.set_facecolor(C_BG)\n",
        "    ax.axis('off')\n",
        "\n",
        "    # 1. The Physical Container Box\n",
        "    rect = patches.Rectangle((0.05, 0.05), 0.9, 0.9, linewidth=6, edgecolor=risk_col, facecolor='#111827', transform=ax.transAxes)\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    # 2. The Title\n",
        "    ax.text(0.5, 0.82, \"FINAL CLINICAL RISK ASSESSMENT\", color=C_TEXT, fontsize=28, ha='center', fontweight='black', transform=ax.transAxes)\n",
        "\n",
        "    # 3. The Big Score\n",
        "    ax.text(0.5, 0.52, f\"{risk_pct}%\", color=risk_col, fontsize=120, ha='center', fontweight='black', transform=ax.transAxes)\n",
        "\n",
        "    # 4. The Progress Bar\n",
        "    ax.barh([0.38], [0.8], color='#222', height=0.05, align='center', transform=ax.transAxes, left=0.1)\n",
        "    ax.barh([0.38], [0.8 * (risk_pct/100)], color=risk_col, height=0.05, align='center', transform=ax.transAxes, left=0.1)\n",
        "\n",
        "    # 5. The Status Label\n",
        "    ax.text(0.5, 0.18, f\"STATUS: {risk_lvl}\", color=risk_col, fontsize=38, ha='center', fontweight='bold',\n",
        "            bbox=dict(facecolor='black', alpha=0.9, edgecolor=risk_col, boxstyle='round,pad=1.2'), transform=ax.transAxes)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# --- RUN ---\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    draw_medical_cockpit(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "dK7Uss-C2wQa",
        "outputId": "c506ebff-d283-46c6-b6a0-841a8ddaedde"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2031324426.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpraat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menv\u001b[0m \u001b[0;31m# line: 456\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate\u001b[0m \u001b[0;31m# line: 365\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0min_main_process\u001b[0m \u001b[0;31m# line: 418\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/combinations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_all_reduce_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmirrored_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_worker_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalues_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtfconfig_cluster_resolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_lib_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/cluster_resolver/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleClusterResolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnionClusterResolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgce_cluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCEClusterResolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkubernetes_cluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKubernetesClusterResolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslurm_cluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSlurmClusterResolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0m_GOOGLE_API_CLIENT_INSTALLED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mgoogleapiclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiscovery\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/googleapiclient/discovery.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMutualTLSChannelError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmtls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# perform version checks against api_core, and emit warnings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mcheck_python_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"google.api_core\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mcheck_dependency_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google.api_core\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/_python_version_support.py\u001b[0m in \u001b[0;36mcheck_python_version\u001b[0;34m(package, today)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[1;32m    209\u001b[0m     \u001b[0mtoday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoday\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mpackage_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_distribution_and_import_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mpython_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/_python_version_support.py\u001b[0m in \u001b[0;36m_get_distribution_and_import_packages\u001b[0;34m(import_package)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_distribution_and_import_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_package\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"\"\"Return a pretty string with distribution & import package names.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mdistribution_package\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_pypi_package_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_package\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     dependency_distribution_and_import_packages = (\n\u001b[1;32m    191\u001b[0m         \u001b[0;34mf\"package {distribution_package} ({import_package})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/_python_version_support.py\u001b[0m in \u001b[0;36m_get_pypi_package_name\u001b[0;34m(module_name)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# Get the mapping of modules to distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mmodule_to_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# Check if the module is found in the mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **API**"
      ],
      "metadata": {
        "id": "ONxzwzQ-UBVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from fastapi.responses import Response, HTMLResponse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import librosa\n",
        "import librosa.display\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import csv\n",
        "import warnings\n",
        "\n",
        "# --- INITIAL SETUP AND GLOBAL RESOURCES ---\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- MODERN DESIGN PALETTE (Kept from original) ---\n",
        "C_BG = '#0B0F19'      # Deep Space Navy\n",
        "C_HL = '#00E676'      # Neon Healthy Green\n",
        "C_WARN = '#FFEA00'    # Neon Warning Yellow\n",
        "C_CRIT = '#FF1744'    # Neon Critical Red\n",
        "C_BLUE = '#2979FF'    # Electric Blue\n",
        "C_PURP = '#D500F9'    # Lethargy Purple\n",
        "C_TEXT = '#FFFFFF'\n",
        "\n",
        "# Global variables for the model\n",
        "yamnet_model = None\n",
        "class_names = []\n",
        "\n",
        "# --- FASTAPI APP ---\n",
        "app = FastAPI(\n",
        "    title=\"Guardian AI Vocal Analysis API\",\n",
        "    description=\"Analyzes vocal biometrics from an audio file using Librosa, Praat (Parselmouth), and YAMNet.\"\n",
        ")\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    \"\"\"Load the heavy YAMNet model once when the app starts.\"\"\"\n",
        "    global yamnet_model, class_names\n",
        "    print(\"Waking up Guardian AI Engine...\")\n",
        "    try:\n",
        "        # Suppress TF messages for cleaner startup\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "        tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "        yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "        class_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\n",
        "        class_names = [row['display_name'] for row in csv.DictReader(open(class_map_path))]\n",
        "        print(\"Guardian AI Engine ready.\")\n",
        "    except Exception as e:\n",
        "        print(f\"CRITICAL ERROR: Failed to load YAMNet model: {e}\")\n",
        "        yamnet_model = None\n",
        "\n",
        "\n",
        "# --- HELPER FUNCTIONS (Kept from original) ---\n",
        "\n",
        "def get_vocal_texture_safe(snd: parselmouth.Sound):\n",
        "    \"\"\"Calculates Jitter and Shimmer safely.\"\"\"\n",
        "    try:\n",
        "        pitch = call(snd, \"To Pitch\", 0.0, 75, 600)\n",
        "        point_process = call([snd, pitch], \"To PointProcess (cc)\")\n",
        "        jitter = call([snd, point_process], \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "        shimmer = call([snd, point_process], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "        if np.isnan(jitter) or jitter == 0: return 0.2, 1.0\n",
        "        return jitter * 100, shimmer * 100\n",
        "    except:\n",
        "        return 0.15, 0.8\n",
        "\n",
        "def calculate_modern_risk(f0_std, wpm, silence_ratio, cry_score, mumble_score, sigh_score, laugh_score):\n",
        "    \"\"\"Calculates risk based on the full Clinical Requirement Table.\"\"\"\n",
        "    score = 10 # Baseline\n",
        "    score += np.clip((30 - f0_std) * 1.5, 0, 30)\n",
        "    score += np.clip((130 - wpm) * 0.4, 0, 30)\n",
        "    score += np.clip(silence_ratio * 0.5, 0, 20)\n",
        "    score += np.clip(cry_score * 100, 0, 25)\n",
        "    score += np.clip(mumble_score * 50, 0, 15)\n",
        "    score += np.clip(sigh_score * 50, 0, 10)\n",
        "    score -= np.clip(laugh_score * 50, 0, 20)\n",
        "\n",
        "    final_pct = int(np.clip(score, 5, 100))\n",
        "\n",
        "    if final_pct > 60: level, col = \"CRITICAL ALERT\", C_CRIT\n",
        "    elif final_pct > 30: level, col = \"MODERATE WARNING\", C_WARN\n",
        "    else: level, col = \"STABLE / HEALTHY\", C_HL\n",
        "    return final_pct, level, col\n",
        "\n",
        "def draw_medical_cockpit(file_path: str) -> bytes:\n",
        "    \"\"\"\n",
        "    Processes audio, calculates metrics, and generates the Matplotlib plot as PNG bytes.\n",
        "    Modified to be non-interactive and return bytes.\n",
        "    \"\"\"\n",
        "    global yamnet_model, class_names\n",
        "\n",
        "    if yamnet_model is None:\n",
        "        raise RuntimeError(\"YAMNet model failed to load at startup. Check startup logs.\")\n",
        "\n",
        "    # --- DATA PROCESSING ---\n",
        "    y, sr = librosa.load(file_path, sr=16000)\n",
        "    duration = librosa.get_duration(y=y, sr=sr)\n",
        "    snd = parselmouth.Sound(file_path)\n",
        "\n",
        "    # Physics Metrics\n",
        "    pitch = snd.to_pitch()\n",
        "    f_vals = pitch.selected_array['frequency']\n",
        "    f_vals[f_vals == 0] = np.nan\n",
        "    f0_std = np.nanstd(f_vals)\n",
        "    if np.isnan(f0_std): f0_std = 12.0\n",
        "\n",
        "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
        "    peaks = librosa.util.peak_pick(onset_env, pre_max=3, post_max=3, pre_avg=3, post_avg=5, delta=0.5, wait=10)\n",
        "    wpm = (len(peaks) / duration) * 60 if duration > 0 else 0\n",
        "\n",
        "    intervals = librosa.effects.split(y, top_db=25)\n",
        "    silence_duration = duration - (sum([i[1]-i[0] for i in intervals])/sr)\n",
        "    silence_ratio = (silence_duration / duration) * 100 if duration > 0 else 0\n",
        "    jitter, shimmer = get_vocal_texture_safe(snd)\n",
        "\n",
        "    # AI YAMNet Scores\n",
        "    scores, _, _ = yamnet_model(tf.cast(y, tf.float32))\n",
        "    m_scores = np.mean(scores.numpy(), axis=0)\n",
        "\n",
        "    def get_val(name):\n",
        "        try:\n",
        "            return m_scores[class_names.index(name)]\n",
        "        except ValueError:\n",
        "            return 0.0\n",
        "\n",
        "    # --- GUARDIAN LABELS EXTRACTION ---\n",
        "    speech_s = get_val('Speech')\n",
        "    sigh_s = get_val('Sigh') + get_val('Breathing') # Combined Anxiety\n",
        "    mumble_s = get_val('Whispering') # Proxy for Lethargy\n",
        "    cry_s = get_val('Crying, sobbing') # Crisis\n",
        "    laugh_s = get_val('Laughter') # Positive\n",
        "\n",
        "    # Risk Calculation\n",
        "    risk_pct, risk_lvl, risk_col = calculate_modern_risk(f0_std, wpm, silence_ratio, cry_s, mumble_s, sigh_s, laugh_s)\n",
        "\n",
        "    # --- UI BUILDER (Modified for API Output) ---\n",
        "    plt.ioff() # Turn off interactive mode\n",
        "    fig, axes = plt.subplots(nrows=10, ncols=1, figsize=(18, 95), facecolor=C_BG)\n",
        "    plt.subplots_adjust(hspace=0.9, bottom=0.05)\n",
        "\n",
        "    # --- PLOT GENERATION (Original logic) ---\n",
        "\n",
        "    # ROW 0: HEADER\n",
        "    axes[0].set_facecolor('#111827')\n",
        "    axes[0].text(0.5, 0.5, \"GUARDIAN AI: BIOMETRIC SCAN\", color=C_TEXT, fontsize=32, ha='center', fontweight='black')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # ROW 1: SPEED\n",
        "    axes[1].barh([0], [200], color='#222', height=0.3)\n",
        "    axes[1].barh([0], [wpm], color=C_BLUE, height=0.3)\n",
        "    axes[1].set_title(f\"1. PSYCHOMOTOR SPEED ({int(wpm)} WPM)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    axes[1].set_xlabel(\"WHAT IS THIS: Measures 'Psychomotor Retardation' via speech frequency.\\nHOW IT HELPS: Depression slows cognitive processing; lower WPM equals clinical lethargy.\", color=C_WARN, fontsize=16, labelpad=15); axes[1].axis('off')\n",
        "\n",
        "    # ROW 2: PROSODY\n",
        "    axes[2].plot(pitch.xs(), f_vals, color=C_HL, linewidth=3)\n",
        "    axes[2].set_title(f\"2. PROSODY CONTOUR (SD: {f0_std:.1f}Hz)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    axes[2].set_xlabel(\"WHAT IS THIS: Tracks the fundamental frequency variance (Vocal Melody).\\nHOW IT HELPS: Flat lines (<15Hz) indicate 'Flat Affect' and clinical emotional numbing.\", color=C_WARN, fontsize=16, labelpad=15)\n",
        "    axes[2].set_facecolor('#0d1117'); axes[2].tick_params(colors=C_TEXT)\n",
        "\n",
        "    # ROW 3: SILENCE\n",
        "    axes[3].pie([100-silence_ratio, silence_ratio], labels=['Speech', 'Silence'], colors=[C_HL, C_BLUE], autopct='%1.1f%%', textprops={'color':\"w\", 'fontsize':18})\n",
        "    axes[3].set_title(\"3. COGNITIVE LOAD ANALYSIS\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    axes[3].set_xlabel(\"WHAT IS THIS: Ratio of unintended gaps. High ratio = Cognitive Distress.\", color=C_WARN, fontsize=16, labelpad=15)\n",
        "\n",
        "    # ROW 4: RADAR (Requires manual handling of polar plot to replace the default axis)\n",
        "    fig.delaxes(axes[4])\n",
        "    ax_radar = fig.add_subplot(10, 1, 5, polar=True); ax_radar.set_facecolor('#111827')\n",
        "    r_labels = ['Sadness', 'Neutral', 'Calm', 'Energy', 'Happiness']\n",
        "    r_vals = [cry_s*60, speech_s*10, silence_ratio/100, 0.4, laugh_s*20]\n",
        "    r_vals_closed = r_vals + [r_vals[0]]\n",
        "    angles = np.linspace(0, 2*np.pi, len(r_labels), endpoint=False)\n",
        "    angles_closed = np.concatenate((angles, [angles[0]]))\n",
        "\n",
        "    ax_radar.fill(angles_closed, r_vals_closed, color=C_BLUE, alpha=0.4); ax_radar.plot(angles_closed, r_vals_closed, color=C_BLUE, linewidth=2)\n",
        "    ax_radar.set_xticks(angles); ax_radar.set_xticklabels(r_labels, color=C_TEXT, fontsize=14)\n",
        "    ax_radar.set_title(\"4. EMOTION RADAR CLASSIFICATION\", color=C_TEXT, fontsize=22, fontweight='bold', pad=40)\n",
        "    axes[4] = ax_radar # Store the new axis object\n",
        "\n",
        "    # ROW 5: PRIVACY (Spectrogram)\n",
        "    ax = axes[5]; S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max), x_axis='time', y_axis='mel', sr=sr, ax=ax, cmap='magma')\n",
        "    ax.set_title(\"5. PRIVACY SHIELD (MEL-SPECTROGRAM)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    ax.set_xlabel(\"PRIVACY: Our AI analyzes these frequency patterns, NOT the words. Safe & Private.\", color=C_HL, fontsize=16, fontweight='bold', labelpad=15)\n",
        "\n",
        "    # ROW 6: TEXTURE\n",
        "    ax = axes[6]; ax.set_facecolor('#0d1117')\n",
        "    ax.scatter(np.random.normal(jitter, 0.04, 100), np.random.normal(shimmer, 0.08, 100), color=C_WARN, alpha=0.6, s=150)\n",
        "    ax.set_title(\"6. VOCAL TEXTURE (Micro-Instability)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    ax.tick_params(colors=C_TEXT) # Added for visibility\n",
        "\n",
        "    # ROW 7: GUARDIAN BEHAVIORAL LOGIC\n",
        "    ax = axes[7]; t_ax = np.linspace(0, duration, scores.shape[0])\n",
        "    ax.set_facecolor('#0d1117')\n",
        "    ax.plot(t_ax, scores[:, class_names.index('Speech')], color=C_HL, label=\"Social Engagement (Speech)\", alpha=0.6)\n",
        "    ax.plot(t_ax, scores[:, class_names.index('Whispering')], color=C_PURP, label=\"Lethargy (Mumble)\", linewidth=2)\n",
        "    ax.plot(t_ax, scores[:, class_names.index('Sigh')] + scores[:, class_names.index('Breathing')], color=C_WARN, label=\"Anxiety (Sighs)\", linewidth=2)\n",
        "    ax.plot(t_ax, scores[:, class_names.index('Crying, sobbing')], color=C_CRIT, label=\"CRISIS (Crying)\", linewidth=4)\n",
        "    ax.set_title(\"7. GUARDIAN LOGIC (Behavioral Detections)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    ax.legend(loc='upper right', facecolor='#111', labelcolor='white', fontsize=12)\n",
        "    ax.set_xlabel(\"WHAT IS THIS: Real-time detection of Lethargy (Mumble), Anxiety (Sighs), and Crisis (Crying).\\nHOW IT HELPS: Maps clinical behaviors to timelines without recording words.\", color=C_WARN, fontsize=16, labelpad=15)\n",
        "    ax.tick_params(colors=C_TEXT)\n",
        "\n",
        "    # ROW 8: TREND\n",
        "    ax = axes[8]; ax.set_facecolor(C_BG)\n",
        "    time_24 = np.linspace(0, 24, 100); act = np.abs(np.sin(time_24/3.5)*40) + 12\n",
        "    ax.fill_between(time_24, act, color=C_HL, alpha=0.2); ax.plot(time_24, act, color=C_HL, linewidth=4)\n",
        "    ax.set_title(\"8. GUARDIAN TREND (24h Social Battery)\", color=C_TEXT, fontsize=22, fontweight='bold', pad=20)\n",
        "    ax.set_xlim(0, 24); ax.tick_params(colors=C_TEXT)\n",
        "\n",
        "    # --- ROW 9: THE OVERFLOW-PROOF RISK BOX ---\n",
        "    ax = axes[9]; ax.set_facecolor(C_BG); ax.axis('off')\n",
        "    rect = patches.Rectangle((0.05, 0.05), 0.9, 0.9, linewidth=6, edgecolor=risk_col, facecolor='#111827', transform=ax.transAxes)\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(0.5, 0.82, \"FINAL CLINICAL RISK ASSESSMENT\", color=C_TEXT, fontsize=28, ha='center', fontweight='black', transform=ax.transAxes)\n",
        "    ax.text(0.5, 0.52, f\"{risk_pct}%\", color=risk_col, fontsize=120, ha='center', fontweight='black', transform=ax.transAxes)\n",
        "    ax.barh([0.38], [0.8], color='#222', height=0.05, align='center', transform=ax.transAxes, left=0.1)\n",
        "    ax.barh([0.38], [0.8 * (risk_pct/100)], color=risk_col, height=0.05, align='center', transform=ax.transAxes, left=0.1)\n",
        "    ax.text(0.5, 0.18, f\"STATUS: {risk_lvl}\", color=risk_col, fontsize=38, ha='center', fontweight='bold',\n",
        "            bbox=dict(facecolor='black', alpha=0.9, edgecolor=risk_col, boxstyle='round,pad=1.2'), transform=ax.transAxes)\n",
        "\n",
        "    # --- RETURN IMAGE DATA AS BYTES ---\n",
        "    buf = io.BytesIO()\n",
        "    try:\n",
        "        fig.savefig(buf, format='png', bbox_inches='tight', facecolor=C_BG)\n",
        "    finally:\n",
        "        plt.close(fig) # IMPORTANT: Frees up memory after plot generation\n",
        "\n",
        "    return buf.getvalue()\n",
        "\n",
        "\n",
        "# --- FASTAPI ENDPOINT ---\n",
        "\n",
        "@app.post(\"/analyze_audio\", response_class=Response, summary=\"Analyze Audio and Generate Cockpit Visualization\")\n",
        "async def analyze_audio_route(audio_file: UploadFile = File(..., description=\"Audio file (e.g., MP3, WAV) for vocal biometric analysis.\")):\n",
        "    \"\"\"\n",
        "    Accepts an audio file, analyzes vocal features, calculates a clinical risk score,\n",
        "    and returns a massive multi-panel visualization as a PNG image.\n",
        "    \"\"\"\n",
        "\n",
        "    if yamnet_model is None:\n",
        "         raise HTTPException(status_code=503, detail=\"AI Model not ready. Please check server logs.\")\n",
        "\n",
        "    temp_file = None\n",
        "    try:\n",
        "        # 1. Save the uploaded file to a temporary location\n",
        "        # This is required because parselmouth/librosa often expect a file path, not just file content\n",
        "        ext = audio_file.filename.split('.')[-1] if '.' in audio_file.filename else 'wav'\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=f\".{ext}\") as tmp:\n",
        "            shutil.copyfileobj(audio_file.file, tmp)\n",
        "            temp_file = tmp.name\n",
        "\n",
        "        # 2. Process the audio and generate the image bytes\n",
        "        image_bytes = draw_medical_cockpit(temp_file)\n",
        "\n",
        "        # 3. Return the image as a response\n",
        "        return Response(content=image_bytes, media_type=\"image/png\")\n",
        "\n",
        "    except HTTPException as e:\n",
        "        raise e\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        raise HTTPException(status_code=400, detail=f\"Audio processing failed. Is the file a valid audio format? Error: {str(e)}\")\n",
        "    finally:\n",
        "        # 4. Clean up the temporary file\n",
        "        if temp_file and os.path.exists(temp_file):\n",
        "            os.remove(temp_file)\n",
        "\n",
        "# Optional: Simple root endpoint for documentation\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"Go to /docs to use the API endpoint: /analyze_audio\"}"
      ],
      "metadata": {
        "id": "5oiGiMHEUNqd"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}